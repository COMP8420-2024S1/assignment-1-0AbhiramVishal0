{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "110ab9fe-4e34-4ecb-8d25-57a8a812712e",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "\n",
    "- Below is the code for requide task, of creating voice bot with response.\n",
    "- I have created voice ivr, for Ace hotels which handles booking and other stuff related to room management of the hotel\n",
    "\n",
    "- pre requisites\n",
    "- Need ollama mistral model installed - \"ollama run mistral\" in background\n",
    "- ffmpg library required to be installed\n",
    "- Required libraries are imported as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e00384d0-6394-41c0-a202-2caeed1c7768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recording...\n",
      "\n",
      "Audio Captured\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription:  I want to cancel my booking.\n",
      "Sentiment: NEGATIVE\n",
      "\n",
      "Recording...\n",
      "\n",
      "Audio Captured\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import librosa\n",
    "from transformers import pipeline\n",
    "import whisper\n",
    "import ollama\n",
    "import numpy as np\n",
    "import wavio\n",
    "\n",
    "# Play the greeting audio\n",
    "def play_audio(data, fs):\n",
    "    sd.play(data, fs)\n",
    "    sd.wait()\n",
    "    \n",
    "def play_audio_file(file_path):\n",
    "    # Read the audio file\n",
    "    wav_obj = wavio.read(file_path)\n",
    "    \n",
    "    # Get data and sampling rate from the Wav object\n",
    "    wav_data = wav_obj.data\n",
    "    fs = wav_obj.rate\n",
    "\n",
    "    # Play the audio\n",
    "    sd.play(wav_data, fs)\n",
    "    sd.wait()\n",
    "    \n",
    "# Step 2: Record live audio using sounddevice\n",
    "def record_audio(file_path, duration=6, fs=44100):\n",
    "    print(\"\\nRecording...\")\n",
    "    audio_data = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='int16')\n",
    "    sd.wait()\n",
    "    print(\"\\nAudio Captured\")\n",
    "    \n",
    "    # Save the audio data as WAV file using wavio\n",
    "    audio_data = audio_data.flatten()\n",
    "    wavio.write(file_path, audio_data, fs, sampwidth=2)\n",
    "    \n",
    "    return audio_data\n",
    "\n",
    "# Transcribe audio using OpenAI's Whisper model\n",
    "def transcribe_audio_whisper(audio_data):\n",
    "    transcriber = pipeline(model=\"openai/whisper-medium\", task=\"automatic-speech-recognition\")\n",
    "    transcription = transcriber(audio_data)\n",
    "    print(\"Transcription:\", transcription['text'])\n",
    "    return transcription['text']\n",
    "\n",
    "# Use local language model with ollama for intent detection\n",
    "def generate_text_with_ollama(prompt):\n",
    "    stream = ollama.chat(\n",
    "        model='mistral',\n",
    "        messages=[{'role': 'user', 'content': \"tell me the intent in one word is booking or cancelling or other in this text -\" + prompt}],\n",
    "        stream=True)\n",
    "    text_list = []\n",
    "    for chunk in stream:\n",
    "        content = chunk['message']['content']\n",
    "        \n",
    "        text_list.append(content)\n",
    "    \n",
    "    if \"book\" or \"booking\" in text_list:\n",
    "        return 1\n",
    "    elif \"cancel\" or \"cancelling\" or \"elling\" in text_list:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "# response basing on intent\n",
    "def identify_intent(intent_status):\n",
    "    if intent_status == 1:\n",
    "        play_audio_file(response1)\n",
    "        record_audio(recorded_audio_path)\n",
    "        play_audio_file(final_response)\n",
    "    elif intent_status == 2:\n",
    "        play_audio_file(response2)\n",
    "        record_audio(recorded_audio_path)\n",
    "        play_audio_file(final_response)\n",
    "    else:\n",
    "        play_audio_file(response3)\n",
    "\n",
    "# Sentiment analysis (using Huggingface sentiment-analysis model)\n",
    "def sentiment_analysis(text):\n",
    "    sentiment_analyzer = pipeline('sentiment-analysis')\n",
    "    result = sentiment_analyzer(text)\n",
    "    print(\"Sentiment:\", result[0]['label'])\n",
    "\n",
    "# Example usage:\n",
    "recorded_audio_path = \"recorded_audio.wav\"\n",
    "greeting_audio_path = \"Hello Welcome to Ace.wav\"\n",
    "response1 = \"response1.wav\"\n",
    "response2 = \"response2.wav\"\n",
    "response3 = \"response3.wav\"\n",
    "final_response = \"finalresponse.wav\"\n",
    "fs = 44100\n",
    "\n",
    "# start of the code\n",
    "play_audio_file(greeting_audio_path)\n",
    "\n",
    "recorded_audio_data = record_audio(recorded_audio_path)\n",
    "\n",
    "recorded_text = transcribe_audio_whisper(recorded_audio_path)\n",
    "sentiment_analysis(recorded_text)\n",
    "\n",
    "prompt_ollama = recorded_text\n",
    "status = generate_text_with_ollama(prompt_ollama)\n",
    "\n",
    "identified_intent = identify_intent(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42d71ff-c982-473d-9a01-7dddbfef2eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f95e954-b7c3-4e52-b0f8-7ee13ba59ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbc078e-8e5b-452b-a2d1-f7c6f04e6d17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
